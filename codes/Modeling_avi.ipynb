{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "973497bf",
      "metadata": {
        "id": "973497bf"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "733f104e",
      "metadata": {
        "id": "733f104e"
      },
      "source": [
        "### imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ecddc71d",
      "metadata": {
        "id": "ecddc71d"
      },
      "outputs": [],
      "source": [
        "# Key\n",
        "import os \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "# Keras\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import callbacks\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "\n",
        "# PyTorch\n",
        "import torchvision\n",
        "\n",
        "# Pre-Trained Models\n",
        "from tensorflow.keras.applications import InceptionV3, Xception, ResNet152V2, ResNet50V2, ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "# Visualization Tools\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "import plotly.figure_factory as ff\n",
        "#import kaleido\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f79c91e5",
      "metadata": {
        "id": "f79c91e5"
      },
      "source": [
        "### Data Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3upBnsz1WWDX",
        "outputId": "2ef70836-9791-411d-c5f8-9677196df4fe"
      },
      "id": "3upBnsz1WWDX",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"drive/My Drive/590_project\")"
      ],
      "metadata": {
        "id": "xzTNeZvhWmdn"
      },
      "id": "xzTNeZvhWmdn",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JemDprCgWmR6",
        "outputId": "85477bce-26d0-4f5a-ac42-06b2c4f6fa67"
      },
      "id": "JemDprCgWmR6",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'590 Project - Presentation.gslides'\n",
            "'Automated Detection of Autism Spectrum Disorder Using a Convolutional Neural Network.pdf'\n",
            " bench_mark_-model-01-0.49.hdf5\n",
            " bench_mark_-model-{epoch:02d}-{val_acc:.2f}.hdf5\n",
            " benchmark_model_history.csv\n",
            " benchmark_model_history.json\n",
            "'Corpus callosum and brain segmentation images.zip'\n",
            " Modeling_avi.ipynb\n",
            " MODEL.ipynb\n",
            " nii2png.ipynb\n",
            " Phenotypic_data_Legend.pdf\n",
            " Phenotypic_V1_0b_preprocessed1.csv\n",
            " Phenotypic_V1_0b_preprocessed1.gsheet\n",
            " scans\n",
            "'TO DO + USEFUL LINKS.gdoc'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e99b2b62",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "e99b2b62",
        "outputId": "adbf2f01-921d-441f-998d-9dbd04cdd429"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  subject  DX_GROUP\n",
              "0   50002         1\n",
              "1   50003         1\n",
              "2   50004         1\n",
              "3   50005         1\n",
              "4   50006         1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59aa08d1-c328-460b-aa2f-a5292b122c46\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "      <th>DX_GROUP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50002</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50003</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50004</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50005</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50006</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59aa08d1-c328-460b-aa2f-a5292b122c46')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-59aa08d1-c328-460b-aa2f-a5292b122c46 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-59aa08d1-c328-460b-aa2f-a5292b122c46');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df = pd.read_csv(\"Phenotypic_V1_0b_preprocessed1.csv\")\n",
        "df = df[[\"subject\",\"DX_GROUP\"]]\n",
        "\n",
        "# map 0 to control group and 1 to autism group\n",
        "df.DX_GROUP = df.DX_GROUP.map({1.0: 1, 2.0: 0})\n",
        "df.subject = df.subject.astype(int).astype(str)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fe8e080",
      "metadata": {
        "id": "0fe8e080"
      },
      "source": [
        "### EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4276f471",
      "metadata": {
        "id": "4276f471"
      },
      "outputs": [],
      "source": [
        "n_classes = 2 \n",
        "classes = [\"Control\",\"Autism\"]\n",
        "class_distribution = [len(df[df['DX_GROUP'] == 0]), len(df[df['DX_GROUP'] == 1])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "61eb97cc",
      "metadata": {
        "id": "61eb97cc"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# plt.figure(figsize = (8,6))\n",
        "# fig = px.pie(names = classes, \n",
        "#              values = class_distribution, \n",
        "#              title = \"Class Distribution\",\n",
        "#              color_discrete_sequence = px.colors.qualitative.Vivid\n",
        "#             )\n",
        "# fig.update_layout({'title':{'x':0.5}})\n",
        "# # fig.write_image('../images/piechart_class.png', format = 'png') # takes forever to write -- manually save image\n",
        "# fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0925f12c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "0925f12c",
        "outputId": "c8a23e31-7920-44a6-d2a7-9d38cc871535"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(x=classes, y=class_distribution)\n",
        "plt.axhline(np.mean(class_distribution), alpha=0.5, linestyle='--', color='k', label=\"Mean Class Count\")\n",
        "plt.title(\"Class Distribution\", size = 15)\n",
        "plt.ylabel(\"Count\", size = 12)\n",
        "plt.xlabel(\"Class\", size = 12)\n",
        "plt.legend(fontsize=12)\n",
        "#plt.savefig(\"../images/barplot_class.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ea2253f",
      "metadata": {
        "id": "4ea2253f"
      },
      "source": [
        "### Create X, y "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "58b23b91",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58b23b91",
        "outputId": "77ddcfbc-71aa-4430-ddf9-fe7a0fc4db5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have 1100 BRAIN MRI scans in the dataset\n",
            "Associated are 1100 labels across 2 classes\n"
          ]
        }
      ],
      "source": [
        "scan_path = \"scans/\"\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "for image_name in os.listdir(scan_path):\n",
        "    image_path = os.path.join(scan_path, image_name)\n",
        "    \n",
        "    x = torchvision.io.read_image(image_path)\n",
        "    # image = plt.imread(image_path)\n",
        "    # image = np.reshape(image, (512,512,1))\n",
        "    x = torchvision.transforms.functional.rotate(x,-180,expand=True)\n",
        "    x = np.array(x)\n",
        "    x = np.reshape(x, (512,512,1))\n",
        "    images.append(x)\n",
        "    \n",
        "    patient_id = image_name[2:-4]\n",
        "    label = df[df[\"subject\"] == patient_id][\"DX_GROUP\"].values[0]\n",
        "    labels.append(label)\n",
        "\n",
        "assert(len(images) == len(labels))\n",
        "print(f\"We have {len(images)} BRAIN MRI scans in the dataset\")\n",
        "print(f\"Associated are {len(labels)} labels across {n_classes} classes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "24602e90",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24602e90",
        "outputId": "67f2fe50-c2c4-4d96-9adf-ab0f11ff7893"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (1100, 512, 512, 1)\n",
            "Shape of y: (1100,)\n"
          ]
        }
      ],
      "source": [
        "X = np.array(images)\n",
        "y = np.array(labels)\n",
        "\n",
        "print(f\"Shape of X: {X.shape}\")\n",
        "print(f\"Shape of y: {y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f92e03b7",
      "metadata": {
        "id": "f92e03b7"
      },
      "outputs": [],
      "source": [
        "# # Set a numpy random seed\n",
        "# np.random.seed(590)\n",
        "\n",
        "# plt.figure(figsize = (10,11))\n",
        "# for i in range(1,10):\n",
        "    \n",
        "#     idx = np.random.randint(len(images))\n",
        "#     image, label = X[idx], int(y[idx])\n",
        "    \n",
        "#     word_label = \"Autism\" if label == 1 else \"Control\"\n",
        "#     plt.subplot(3, 3, i)\n",
        "#     im = X[idx]\n",
        "#     plt.title(word_label)\n",
        "#     plt.imshow(im)\n",
        "\n",
        "# #plt.savefig(\"../images/3x3_ImageGrid.png\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7PacW_UygcKF"
      },
      "id": "7PacW_UygcKF",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "924fb321",
      "metadata": {
        "id": "924fb321"
      },
      "source": [
        "### Create Train_Test_Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "422edd72",
      "metadata": {
        "id": "422edd72"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=322)\n",
        "\n",
        "train_data = (X_train, y_train)\n",
        "test_data = (X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8726fa66",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8726fa66",
        "outputId": "3addb425-d5b8-4aef-9dc5-6370ba06fbe6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(825, 512, 512, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d46477cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d46477cb",
        "outputId": "e9e028d6-2b0c-4bb2-fc97-ba7f05f67853"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(825,)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toCQRuqnikLX",
        "outputId": "cc7e5e12-dd86-4ab7-f28b-d481be7e0b1f"
      },
      "id": "toCQRuqnikLX",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(275, 512, 512, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Auto encoder"
      ],
      "metadata": {
        "id": "2LscUjjShBr8"
      },
      "id": "2LscUjjShBr8"
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers"
      ],
      "metadata": {
        "id": "eAx0q5KMg9Yo"
      },
      "id": "eAx0q5KMg9Yo",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # refrence from lecture code\n",
        "# # Normalize and reshape the datax\n",
        "# x_train = X_train/np.max(X_train) \n",
        "# x_train = x_train.reshape(825,512*512)\n",
        "\n",
        "# x_test = X_test/np.max(X_test) \n",
        "# x_test = x_test.reshape(275,512*512)"
      ],
      "metadata": {
        "id": "Zwm7C751iXLF"
      },
      "id": "Zwm7C751iXLF",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # INSERT CODE HERE\n",
        "# # Define method to build auto-encoder with bottleneck model\n",
        "# def train_ae(n_bottleneck,x_train,y_train):\n",
        "\n",
        "\n",
        "#     model = models.Sequential()\n",
        "    \n",
        "#     model.add(layers.Conv2D(input_shape=(512,512,1), filters= 32, kernel_size = (3, 3), activation='relu', padding='same'))\n",
        "#     model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
        "#     #model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "#     #model.add(layers.MaxPooling2D( (2, 2), padding='same'))\n",
        "#     #model.add(layers.Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
        "#     model.add(layers.Flatten())\n",
        "#     model.add(layers.Dense(n_bottleneck))\n",
        "\n",
        "\n",
        "#     # Compile model\n",
        "#     model.compile(optimizer='rmsprop', loss='mean_squared_error',  metrics=['accuracy'])\n",
        "\n",
        "#     # Set callbacks\n",
        "#     set_callbacks = [tf.keras.callbacks.EarlyStopping(patience=3)]\n",
        "    \n",
        "#     # Fit the model with input data\n",
        "#     results = model.fit(x_train, x_train, \n",
        "#                         epochs=10, batch_size=1000, \n",
        "#                         validation_split=0.2, callbacks=set_callbacks, verbose=True)\n",
        "\n",
        "#     # Get training and testing loss at final epoch\n",
        "#     return (model,results.history['loss'][-1], results.history['val_loss'][-1])"
      ],
      "metadata": {
        "id": "lU1JRWExg9WT"
      },
      "id": "lU1JRWExg9WT",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # INSERT CODE HERE\n",
        "# bottleneck_grid = list(range(1,200,10))\n",
        "# train_errors = []\n",
        "# val_errors = []\n",
        "# for bottleneck in bottleneck_grid:\n",
        "#     print(f\"Running for {bottleneck}\")\n",
        "#     result = train_ae(bottleneck,X_train,y_train)\n",
        "#     train_errors.append(result[1])\n",
        "#     val_errors.append(result[2])"
      ],
      "metadata": {
        "id": "jv4DF_Vwg9T-"
      },
      "id": "jv4DF_Vwg9T-",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fky34HwEg9RH"
      },
      "id": "fky34HwEg9RH",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "41bf8bad",
      "metadata": {
        "id": "41bf8bad"
      },
      "source": [
        "### Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "32ec43ad",
      "metadata": {
        "id": "32ec43ad"
      },
      "outputs": [],
      "source": [
        "def save_history(history, model_name):\n",
        "    #convert the history.history dict to a pandas DataFrame:     \n",
        "    hist_df = pd.DataFrame(history.history) \n",
        "\n",
        "    # save to json:  \n",
        "    hist_json_file = 'models/'+model_name+'_history.json' \n",
        "    with open(hist_json_file, mode='w') as f:\n",
        "        hist_df.to_json(f)\n",
        "\n",
        "    # or save to csv: \n",
        "    hist_csv_file = 'models/'+model_name+'_history.csv'\n",
        "    with open(hist_csv_file, mode='w') as f:\n",
        "        hist_df.to_csv(f)\n",
        "        \n",
        "def plot_accuracy_from_history(history, isinception=False):\n",
        "    color = sns.color_palette()\n",
        "    if(isinception == False):\n",
        "        acc = history.history['acc']\n",
        "        val_acc = history.history['val_acc']\n",
        "    else:\n",
        "        acc = history.history['accuracy']\n",
        "        val_acc = history.history['val_accuracy']\n",
        "    \n",
        "\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    sns.lineplot(epochs, acc, label='Training Accuracy')\n",
        "    sns.lineplot(epochs, val_acc,label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "    plt.figure()\n",
        "    plt.show()\n",
        "    \n",
        "def plot_loss_from_history(history):\n",
        "    color = sns.color_palette()\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    \n",
        "    epochs = range(len(loss))\n",
        "    \n",
        "    sns.lineplot(epochs, loss,label='Training Loss')\n",
        "    sns.lineplot(epochs, val_loss, label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.figure()\n",
        "    plt.show()\n",
        "    \n",
        "def do_history_stuff(history, history_file_name, isinception=False):\n",
        "    save_history(history, history_file_name)\n",
        "    plot_accuracy_from_history(history, isinception)\n",
        "    plot_loss_from_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "c26d79f1",
      "metadata": {
        "id": "c26d79f1"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# epoch config\n",
        "benchmark_epoch = 10\n",
        "vgg_epoch = 60\n",
        "resnet_epoch = 60\n",
        "inception_epoch = 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "058e143b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "058e143b",
        "outputId": "49a977e0-b02a-48ca-d08a-91e0937296b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 506, 506, 32)      1600      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 252, 252, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2032128)           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               260112512 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 260,114,241\n",
            "Trainable params: 260,114,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#random architecture\n",
        "benchmark_model = keras.Sequential()\n",
        "# Input here is 4D array (batchsize, height, width, channels) - we have already created the train_generator with batch size 32\n",
        "# 32 Images of size each 150x150 with 3 color channels will be input into this layer\n",
        "benchmark_model.add(layers.Conv2D(32, kernel_size=7, activation='relu', input_shape=(512,512,1)))\n",
        "benchmark_model.add(layers.MaxPooling2D(pool_size=(4,4), strides=(2,2)))\n",
        "#benchmark_model.add(layers.Conv2D(32, kernel_size=5, activation='relu'))\n",
        "#benchmark_model.add(layers.MaxPooling2D(pool_size=(4,4), strides=(2,2)))\n",
        "benchmark_model.add(layers.Flatten())\n",
        "benchmark_model.add(layers.Dense(128,activation='relu'))\n",
        "benchmark_model.add(layers.Dense(1,activation='softmax'))\n",
        "\n",
        "benchmark_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "benchmark_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "570bdc61",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "570bdc61",
        "outputId": "160861f8-d5c3-4ef0-8ce4-e3983f78b79d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-e442a8bc4cf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m history = benchmark_model.fit(x = X_train,y = y_train,\n\u001b[0m\u001b[1;32m      6\u001b[0m                                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbenchmark_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "filepath = \"models/bench_mark_-model-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=5, min_lr=0.000002)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "history = benchmark_model.fit(x = X_train,y = y_train,\n",
        "                                epochs=benchmark_epoch, \n",
        "                                verbose=1, \n",
        "                                validation_split= 0.2,\n",
        "                                callbacks=[reduce_lr,early_stopping,checkpoint])\n",
        "\n",
        "benchmark_model.save(filepath)\n",
        "do_history_stuff(history, 'benchmark_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "d305c1cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d305c1cf",
        "outputId": "767211e5-b2ac-4701-d327-4c68243e9619"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(825, 512, 512, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import GlobalMaxPooling2D, GlobalAveragePooling2D, Dropout, Dense, Input, Conv2D, MaxPooling2D, Flatten,MaxPooling3D"
      ],
      "metadata": {
        "id": "MDdmQbmYrdEU"
      },
      "id": "MDdmQbmYrdEU",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### VGG16 Model"
      ],
      "metadata": {
        "id": "Mg7akV4U0xm5"
      },
      "id": "Mg7akV4U0xm5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8ea1bbb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8ea1bbb",
        "outputId": "12948bbb-6ddd-422a-ddef-1dfbbf214e78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 0.4894 \n",
            "Epoch 1: val_acc improved from -inf to 0.42424, saving model to vgg_16_-saved-model-01-acc-0.42.hdf5\n",
            "21/21 [==============================] - 1513s 73s/step - loss: 0.0000e+00 - acc: 0.4894 - val_loss: 0.0000e+00 - val_acc: 0.4242\n",
            "Epoch 2/10\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 0.4894 \n",
            "Epoch 2: val_acc did not improve from 0.42424\n",
            "21/21 [==============================] - 1515s 73s/step - loss: 0.0000e+00 - acc: 0.4894 - val_loss: 0.0000e+00 - val_acc: 0.4242\n",
            "Epoch 3/10\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0000e+00 - acc: 0.4894 \n",
            "Epoch 3: val_acc did not improve from 0.42424\n",
            "21/21 [==============================] - 1519s 73s/step - loss: 0.0000e+00 - acc: 0.4894 - val_loss: 0.0000e+00 - val_acc: 0.4242\n",
            "Epoch 4/10\n",
            " 2/21 [=>............................] - ETA: 18:28 - loss: 0.0000e+00 - acc: 0.5156"
          ]
        }
      ],
      "source": [
        "vgg16_model = VGG16(pooling='avg', weights=None, include_top=False, input_shape=(512,512,1))\n",
        "for layers in vgg16_model.layers:\n",
        "            layers.trainable=False\n",
        "last_output = vgg16_model.layers[-1].output\n",
        "vgg_x = Flatten()(last_output)\n",
        "vgg_x = Dense(128, activation = 'relu')(vgg_x)\n",
        "vgg_x = Dense(1, activation = 'softmax')(vgg_x)\n",
        "vgg16_final_model = keras.Model(vgg16_model.input, vgg_x)\n",
        "vgg16_final_model.compile(loss = 'categorical_crossentropy', optimizer= 'adam', metrics=['acc'])\n",
        "\n",
        "# VGG16\n",
        "number_of_epochs = 10\n",
        "vgg16_filepath = 'models/vgg_16_'+'-saved-model-{epoch:02d}-acc-{val_acc:.2f}.hdf5'\n",
        "vgg_checkpoint = tf.keras.callbacks.ModelCheckpoint(vgg16_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "vgg_early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
        "vgg16_history = vgg16_final_model.fit(x = X_train,\n",
        "                                      y = y_train, \n",
        "                                      epochs = number_of_epochs ,\n",
        "                                      validation_split = 0.2,\n",
        "                                      callbacks=[vgg_checkpoint,vgg_early_stopping],\n",
        "                                      verbose=1)\n",
        "\n",
        "do_history_stuff(vgg16_history, 'vgg16_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2287b77b",
      "metadata": {
        "id": "2287b77b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ResNet Model"
      ],
      "metadata": {
        "id": "ziG1__oF07Ms"
      },
      "id": "ziG1__oF07Ms"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "779eb40d",
      "metadata": {
        "id": "779eb40d"
      },
      "outputs": [],
      "source": [
        "ResNet50_model = ResNet50(weights=None, include_top=False, input_shape=(512,512,1), classes=2)\n",
        "\n",
        "for layers in ResNet50_model.layers:\n",
        "    layers.trainable=True\n",
        "\n",
        "opt = SGD(lr=0.01,momentum=0.7)\n",
        "# resnet50_x = Conv2D(64, (3, 3), activation='relu')(ResNet50_model.output)\n",
        "# resnet50_x = MaxPooling2D(pool_size=(3, 3))(resnet50_x)\n",
        "resnet50_x = Flatten()(ResNet50_model.output)\n",
        "resnet50_x = Dense(256,activation='relu')(resnet50_x)\n",
        "resnet50_x = Dense(1,activation='softmax')(resnet50_x)\n",
        "resnet50_x_final_model = Model(inputs=ResNet50_model.input, outputs=resnet50_x)\n",
        "resnet50_x_final_model.compile(loss = 'categorical_crossentropy', optimizer= opt, metrics=['acc'])\n",
        "\n",
        "number_of_epochs = resnet_epoch\n",
        "resnet_filepath = 'models/resnet50'+'-saved-model-{epoch:02d}-val_acc-{val_acc:.2f}.hdf5'\n",
        "resnet_checkpoint = tf.keras.callbacks.ModelCheckpoint(resnet_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "resnet_early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=5, min_lr=0.000002)\n",
        "callbacklist = [resnet_checkpoint,resnet_early_stopping,reduce_lr]\n",
        "resnet50_history = resnet50_x_final_model.fit(train_generator, epochs = number_of_epochs ,validation_data = validation_generator,callbacks=callbacklist,verbose=1)\n",
        "\n",
        "do_history_stuff(resnet50_history, 'resnet50_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "192c9e19",
      "metadata": {
        "id": "192c9e19"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### InceptionV3 Model"
      ],
      "metadata": {
        "id": "mgrEU0Cl1XRl"
      },
      "id": "mgrEU0Cl1XRl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8375996d",
      "metadata": {
        "id": "8375996d"
      },
      "outputs": [],
      "source": [
        "InceptionV3_model = InceptionV3(input_shape=(150,150,3),weights='imagenet', include_top=False)\n",
        "for layer in InceptionV3_model.layers[:249]:\n",
        "   layer.trainable = False\n",
        "for layer in InceptionV3_model.layers[249:]:\n",
        "   layer.trainable = True\n",
        "InceptionV3_last_output = InceptionV3_model.output\n",
        "InceptionV3_maxpooled_output = Flatten()(InceptionV3_last_output)\n",
        "InceptionV3_x = Dense(1024, activation='relu')(InceptionV3_maxpooled_output)\n",
        "InceptionV3_x = Dropout(0.5)(InceptionV3_x)\n",
        "InceptionV3_x = Dense(6, activation='softmax')(InceptionV3_x)\n",
        "InceptionV3_x_final_model = Model(inputs=InceptionV3_model.input,outputs=InceptionV3_x)\n",
        "InceptionV3_x_final_model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "number_of_epochs = inception_epoch\n",
        "inception_filepath = 'models/inceptionv3_'+'-saved-model-{epoch:02d}-loss-{loss:.2f}.hdf5'\n",
        "inception_checkpoint = tf.keras.callbacks.ModelCheckpoint(inception_filepath, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
        "inception_early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
        "inceptionv3_history = InceptionV3_x_final_model.fit(train_generator, epochs = number_of_epochs, validation_data = validation_generator,callbacks=[inception_checkpoint,inception_early_stopping],verbose=1)\n",
        "\n",
        "do_history_stuff(inceptionv3_history, 'inceptionv3_model', True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bfd8d01",
      "metadata": {
        "id": "7bfd8d01"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RzUk5m6P1qYA"
      },
      "id": "RzUk5m6P1qYA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8bc31fe5",
      "metadata": {
        "id": "8bc31fe5"
      },
      "source": [
        "### Load Model and perform Predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_best_model = keras.models.load_model('vgg_16_-saved-model-01-acc-0.42.hdf5')\n",
        "resnet_best_model = keras.models.load_model('resnet50-saved-model-11-val_acc-0.44.hdf5')\n",
        "inception_best_model = keras.models.load_model('inceptionv3_-saved-model-03-loss-0.22.hdf5')\n",
        "benchmark_model = keras.models.load_model('bench_mark_-model-01-0.49.hdf5')"
      ],
      "metadata": {
        "id": "Njks2woK1qTT"
      },
      "id": "Njks2woK1qTT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mode(my_list):\n",
        "    ct = Counter(my_list)\n",
        "    max_value = max(ct.values())\n",
        "    return ([key for key, value in ct.items() if value == max_value])"
      ],
      "metadata": {
        "id": "kY4ssj4m1qQ8"
      },
      "id": "kY4ssj4m1qQ8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_value = []\n",
        "combined_model_pred = []\n",
        "vgg_pred = []\n",
        "resnet_pred = []\n",
        "inception_pred = []\n",
        "benchmark_model_pred = []"
      ],
      "metadata": {
        "id": "0J1kLPGA1qOn"
      },
      "id": "0J1kLPGA1qOn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### :Combining the best models of VGG16, Resnet50 & InceptionV3¶\n"
      ],
      "metadata": {
        "id": "NUTL8B9a2EEB"
      },
      "id": "NUTL8B9a2EEB"
    },
    {
      "cell_type": "code",
      "source": [
        "count = X_test.shape[0]\n",
        "i = 0\n",
        "for i in range(count):\n",
        "    true_value.append(y_test[i])\n",
        "\n",
        "    test = X_test[i]\n",
        "    #vgg\n",
        "    vgg16_image_prediction = np.argmax(vgg_best_model.predict(test))\n",
        "    vgg_pred.append(vgg16_image_prediction)\n",
        "\n",
        "    #resnet\n",
        "    resnet50_image_prediction = np.argmax(resnet_best_model.predict(test))\n",
        "    resnet_pred.append(resnet50_image_prediction)\n",
        "\n",
        "    #inception\n",
        "    inception_image_prediction = np.argmax(inception_best_model.predict(test))\n",
        "    inception_pred.append(inception_image_prediction)\n",
        "\n",
        "    #benchmark\n",
        "    bench_image_prediction = np.argmax(benchmark_model.predict(test))\n",
        "    benchmark_model_pred.append(bench_image_prediction)\n",
        "\n",
        "    #giving vgg16 high priority if they all predict something different\n",
        "    image_prediction = mode([vgg16_image_prediction, resnet_50_image_prediction, inception_image_prediction])                                  \n",
        "    combined_model_pred.append(image_prediction)\n",
        "    "
      ],
      "metadata": {
        "id": "2kZVsvuj1qMj"
      },
      "id": "2kZVsvuj1qMj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p1dpX8CM1qKL"
      },
      "id": "p1dpX8CM1qKL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "09ed00eb",
      "metadata": {
        "id": "09ed00eb"
      },
      "source": [
        "### Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "#from mlxtend.plotting import plot_confusion_matrix\n",
        "def clf_report(true_value, model_pred):\n",
        "    \n",
        "    classes = validation_generator.class_indices.keys()\n",
        "    TP_count = [true_value[i] == model_pred[i] for i in range(len(true_value))]\n",
        "    model_accuracy = np.sum(TP_count)/len(TP_count)\n",
        "    print('Model Accuracy', model_accuracy)\n",
        "    \n",
        "    plt.figure(figsize=(7,7))\n",
        "    cm = confusion_matrix(true_value,model_pred)\n",
        "    plt.imshow(cm,interpolation='nearest',cmap=plt.cm.viridis)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    thresh = cm.max()*0.8\n",
        "    for i,j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n",
        "        plt.text(j,i,cm[i,j],\n",
        "                horizontalalignment=\"center\",\n",
        "                color=\"black\" if cm[i,j] > thresh else \"white\")\n",
        "        pass\n",
        "    \n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    pass\n",
        "    \n",
        "    print(classification_report(true_value, model_pred, target_names = list(classes)))"
      ],
      "metadata": {
        "id": "UjsctMVl1qH2"
      },
      "id": "UjsctMVl1qH2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40bacde2",
      "metadata": {
        "id": "40bacde2"
      },
      "outputs": [],
      "source": [
        "#combined vote\n",
        "combined_model_pred = [ c[0] for c in combined_model_pred]\n",
        "clf_report(true_value, combined_model_pred)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG model classification report\n",
        "clf_report(true_value, vgg_pred)"
      ],
      "metadata": {
        "id": "HQVAnKBs9dhE"
      },
      "id": "HQVAnKBs9dhE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resnet50 model classification report\n",
        "clf_report(true_value, resnet_pred)"
      ],
      "metadata": {
        "id": "UlEYN0rK9fvh"
      },
      "id": "UlEYN0rK9fvh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inception model classification report\n",
        "clf_report(true_value, inception_pred)"
      ],
      "metadata": {
        "id": "pusXPS_k9hum"
      },
      "id": "pusXPS_k9hum",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#benchmark model\n",
        "clf_report(true_value, benchmark_model_pred)"
      ],
      "metadata": {
        "id": "p2vgAngN9jga"
      },
      "id": "p2vgAngN9jga",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 ('ANLY590')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "d348d923fb7d7aac2ad5099f4ef34c680f84ded67450cd5aee56b0b86db0f2b0"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}